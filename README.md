# R√©alisez une analyse de sentiments gr√¢ce au Deep Learning

---

# AirParadis ‚Äì Analyse de sentiment des tweets & d√©ploiement MLOps

Ce projet met en place un prototype complet d‚Äôanalyse de sentiment pour la compagnie a√©rienne **Air Paradis**.

Objectif : pr√©dire automatiquement si un tweet est **positif** ou **n√©gatif**, comparer plusieurs approches de mod√©lisation, puis d√©ployer un **service de pr√©diction** utilisable via une API et une interface Streamlit, en appliquant une d√©marche inspir√©e **MLOps** (tracking, versionning, tests, CI, monitoring, alertes).

---

## 1. Architecture globale

Le projet est organis√© autour de trois briques :

1. **Mod√©lisation**

   - Baseline : TF-IDF + R√©gression Logistique (mod√®le d√©ploy√©).
   - Mod√®le avanc√© : r√©seau de neurones avec word embeddings (GloVe + un autre embedding).
   - Mod√®le avanc√© BERT (ModernBERT) pour √©valuer l‚Äôapport des Transformers.

2. **Industrialisation / MLOps**

   - Tracking des exp√©riences avec **MLflow**.
   - S√©rialisation des mod√®les (artifacts).
   - Tests unitaires avec **pytest**.
   - CI via **GitHub Actions**.

3. **Mise en production & Monitoring**
   - API REST avec **FastAPI** pour exposer le mod√®le.
   - Interface **Streamlit** pour tester l‚ÄôAPI et remonter du feedback.
   - Logging des mauvaises pr√©dictions dans un fichier JSON.
   - Compteurs de performance + seuil d‚Äôalerte.
   - Envoi d‚Äôemail via **Mailtrap** lorsqu‚Äôil y a trop de pr√©dictions erron√©es.

---

## 2. Organisation du d√©p√¥t

Arborescence principale :

```text
.
‚îú‚îÄ‚îÄ api/                    # API FastAPI (mod√®le de scoring + endpoints)
‚îÇ   ‚îú‚îÄ‚îÄ main.py             # Entr√©e FastAPI (routes, monitoring, alertes)
‚îÇ   ‚îú‚îÄ‚îÄ model_loader.py     # Chargement du mod√®le TF-IDF + pipeline de pr√©diction
‚îÇ   ‚îî‚îÄ‚îÄ schemas.py          # Sch√©mas Pydantic (entr√©es / sorties)
‚îÇ
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app.py    # Interface Streamlit (pr√©diction + monitoring)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 1_exploration.ipynb       # EDA (exploration des donn√©es)
‚îÇ   ‚îú‚îÄ‚îÄ 2_preprocessing.ipynb     # Analyse des diff√©rents pr√©traitements NLTK
‚îÇ   ‚îú‚îÄ‚îÄ 3_modele_simple.ipynb     # TF-IDF + R√©gression Logistique (+ MLflow)
‚îÇ   ‚îú‚îÄ‚îÄ 4_modele_avance.ipynb     # R√©seau de neurones + embeddings (+ MLflow)
‚îÇ   ‚îú‚îÄ‚îÄ 5_modele_bert.ipynb       # ModernBERT / Transformers (+ MLflow)
‚îÇ   ‚îî‚îÄ‚îÄ 6_comparaison.ipynb       # Comparaison des mod√®les / r√©sultats
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py          # Fonctions de nettoyage/lemmatisation
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ tfidf_logreg.joblib       # Mod√®le TF-IDF + LogReg s√©rialis√© (mod√®le d√©ploy√©)
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py               # Tests unitaires de l‚ÄôAPI FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ test_model_loader.py      # Tests de chargement du mod√®le / pr√©diction
‚îÇ   ‚îî‚îÄ‚îÄ test_preprocessing.py     # Tests du pr√©traitement NLTK
‚îÇ
‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ feedback.log              # Logs JSON des mauvaises pr√©dictions + alertes
‚îÇ
‚îú‚îÄ‚îÄ data/
    ‚îú‚îÄ‚îÄ embeddings/               # Source pour Fastext (wiki-news-300d-1M-subword.vec) et Glove (glove.twitter.27B.200d.txt)
‚îÇ   ‚îî‚îÄ‚îÄ training.1600000.processed.noemoticon.csv (*non versionn√©* -> trop volumineux -> check at : https://www.kaggle.com/datasets/kazanova/sentiment140/data)
‚îÇ
‚îú‚îÄ‚îÄ run.sh                   # Script de lancement (FastAPI + Streamlit + NLTK)(uniquement sur Replit)
‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances du projet
‚îú‚îÄ‚îÄ .gitignore               # Exclusion des donn√©es brutes, env, etc.
‚îÇ
‚îî‚îÄ‚îÄ .github/workflows/...
    ‚îî‚îÄ‚îÄ ci.yml               # CI GitHub Actions (installation + pytest)

```

---

Les gros fichiers (dataset CSV, venv, artefacts temporaires, etc.) sont exclus du d√©p√¥t via .gitignore.

---

## 3. Donn√©es utilis√©es

Nous utilisons le dataset de tweets annot√©s binaire :

- Fichier attendu : data/training.1600000.processed.noemoticon.csv

- Contenu : 1,6 million de tweets, avec un label binaire (0 = n√©gatif, 4 = positif).

- Avant mod√©lisation, les labels sont remapp√©s en 0 (n√©gatif) / 1 (positif).

Pour faire tourner les notebooks, il faut placer le CSV dans le dossier data/ √† la racine du projet.

---

## 4. Installation locale

### 4.1. Pr√©requis

Python 3.11

git

environnement virtuel type env/venv

### 4.2. Cloner le d√©p√¥t et installer les d√©pendances

git clone git@github.com:El-GuiGui/Realisez-une-analyse-de-sentiments-grace-au-Deep-Learning.git
cd <"votre dossier">

-> Cr√©ation d'un environnement virtuel
python -m venv env

Activer :
source env/bin/activate # Linux / macOS
-> ou
env\Scripts\activate # Windows

# Installation des d√©pendances

pip install -r requirements.txt

### 4.3. T√©l√©charger les ressources NLTK

Pour que le pr√©traitement fonctionne (et les tests aussi), il faut t√©l√©charger les ressources NLTK utilis√©es :

python -c "import nltk; nltk.download('stopwords'); nltk.download('punkt'); nltk.download('punkt_tab'); nltk.download('wordnet')"

Pour certaines plateformes (Replit, CI GitHub), ce t√©l√©chargement est fait automatiquement via script (run.sh pour replit par exemple ou direct via workflow GitHub Actions).

---

## 5. Entra√Æner les mod√®les et suivre les exp√©riences (MLflow)

### 5.1. Baseline : TF-IDF + R√©gression Logistique

1. Ouvrir le notebook : notebooks/3_modele_simple.ipynb.

2. Ex√©cuter les cellules :

- chargement des donn√©es,

- pr√©traitement simple via scripts/preprocessing.py,

- split train/test (split fixe partag√© par tous les mod√®les),

- entra√Ænement du pipeline TF-IDF + LogReg,

- logging des m√©triques dans MLflow,

- s√©rialisation du mod√®le dans models/tfidf_logreg.joblib.

Ce fichier .joblib est celui qui sera utilis√© par l‚ÄôAPI.

### 5.2. Mod√®le avanc√© (embeddings + r√©seau de neurones)

1. Ouvrir notebooks/4_modele_avance.ipynb.

2. Utiliser le pr√©traitement ‚Äúavanc√©‚Äù.

3. Charger les embeddings (GloVe + second embedding).

4. Entra√Æner le mod√®le (LSTM ici pr√©sent).

5. Logger dans MLflow : hyperparam√®tres, m√©triques, figures (courbes d‚Äôaccuracy, matrices de confusion).

### 5.3. Mod√®le ModernBERT / Transformers

1. Ouvrir notebooks/5_modele_bert.ipynb.

2. Tokenisation avec le tokenizer ModernBERT.

3. Entra√Ænement sur un sous-√©chantillon (pour respecter les contraintes de ressources ou contrainte de l'environnement local).

4. Logging des exp√©riences dans MLflow.

### 5.4. Visualiser les runs MLflow

Depuis la racine du projet (dans la console):

mlflow ui

Puis ouvrir l‚ÄôURL indiqu√©e (http://127.0.0.1:5000) pour comparer les exp√©riences (baseline, embeddings, BERT).

---

## 6. Lancer l‚ÄôAPI de pr√©diction

### 6.1. V√©rifier le mod√®le s√©rialis√©

Assurez-vous que le fichier suivant existe (g√©n√©r√© par le notebook 3) :

models/tfidf_logreg.joblib

C‚Äôest ce fichier que api/model_loader.py charge au d√©marrage.

### 6.2. Lancer FastAPI en local

Depuis la racine du projet (environnement virtuel activ√©) :

uvicorn api.main:app --reload

L‚ÄôAPI est alors disponible par d√©faut sur :

http://127.0.0.1:8000

La documentation interactive est accessible √† :

http://127.0.0.1:8000/docs

---

## 7. Lancer l‚Äôinterface Streamlit

Dans app/streamlit_app.py, veillez √† ce que l‚ÄôURL de l‚ÄôAPI soit bien locale si vous travaillez en local :

API_BASE_URL = "http://127.0.0.1:8000"
(commenter la ligne replit)

Puis lancer Streamlit :

streamlit run app/streamlit_app.py

Acc√®s local :

http://localhost:8501/

L‚Äôinterface web permet :

- D‚Äôentrer un tweet,

- De lancer une pr√©diction (appel √† l‚ÄôAPI /predict),

- De voir le label (positif / n√©gatif) et la probabilit√©,

- De donner un feedback (üëç / üëé) qui sera envoy√© √† /feedback pour le monitoring.

---

## 8. Endpoints principaux de l‚ÄôAPI

'GET /health'

- V√©rifie que l‚ÄôAPI est d√©marr√©e.

- R√©ponse : { "status": "ok" }.

'POST /predict'

- Entr√©e :

{ "text": "I love this airline, best flight ever!" }

- Sortie :

{
"label": 1,
"label_str": "positive",
"proba": 0.93
}

Le texte est pr√©trait√© via preprocess_simple, puis pass√© dans le pipeline TF-IDF + LogReg charg√© en m√©moire.

'POST /feedback'

- Entr√©e :

{
"text": "tweet original",
"prediction": 1,
"proba": 0.93,
"is_correct": false
}

- Si is_correct est false, l‚ÄôAPI log une mauvaise pr√©diction dans logs/feedback.log et met √† jour les compteurs/alertes.

- Sortie :

{ "status": "received" }

### Endpoints de monitoring (si activ√©s dans main.py)

'GET /stats'
‚Üí retourne le nombre total de pr√©dictions, le nombre de pr√©dictions jug√©es erron√©es, et le taux d‚Äôerreur global.

'GET /wrong_feedbacks'
‚Üí retourne les derniers tweets signal√©s comme mal pr√©dits (texte, label pr√©dit, proba, timestamp).

Ces endpoints sont consomm√©s par l‚Äôonglet ‚ÄúMonitoring‚Äù de l‚Äôinterface Streamlit.

---

## 9. Monitoring & alertes

### 9.1. Logging structur√©

Chaque mauvaise pr√©diction signal√©e par un utilisateur est enregistr√©e comme une ligne JSON dans :

'logs/feedback.log'

Exemple :

{
"timestamp": "2025-01-01T10:15:32Z",
"type": "WRONG_PREDICTION",
"text": "Nice airline but it's not a good airline company",
"prediction": 1,
"proba": 0.73
}

Une entr√©e de type ALERT est ajout√©e lorsqu‚Äôun seuil est franchi.

### 9.2. Seuil d‚Äôalerte

- Si 3 mauvaises pr√©dictions ou plus sont enregistr√©es sur une fen√™tre de 5 minutes, alors une alerte est d√©clench√©e :

  - √âcriture d‚Äôun log ALERT dans feedback.log,

  - Envoi d‚Äôun email selon la configuration SMTP avec les informations essentielles.

### 9.3. Configuration des emails (Mailtrap)

Le projet utilise des variables d‚Äôenvironnement pour l‚Äôalerte email :

- ALERT_EMAIL_ENABLED (True / False)

- ALERT_EMAIL_FROM

- ALERT_EMAIL_TO

- ALERT_EMAIL_SMTP (par ex. sandbox.smtp.mailtrap.io)

- ALERT_EMAIL_PORT (par d√©faut 587)

- ALERT_EMAIL_PASSWORD (token ou mot de passe SMTP)

En local, on peut les d√©finir via un fichier .env (non versionn√©) ou directement dans l‚Äôenvironnement du syst√®me.

---

## 10. Int√©gration continue (CI)

Le d√©p√¥t contient un workflow GitHub Actions qui :

- Installe Python et les d√©pendances.

- T√©l√©charge les ressources NLTK n√©cessaires (stopwords, punkt, etc.).

- Lance pytest sur le dossier tests/.

Objectif : s‚Äôassurer que :

- L‚ÄôAPI d√©marre correctement,

- Le mod√®le est bien chargeable,

- Le pr√©traitement se comporte comme attendu,

- Les modifications futures ne cassent pas la cha√Æne de pr√©diction.

---

## 11. Limites et pistes d‚Äôam√©lioration

Quelques axes possibles si le projet devait aller plus loin :

- D√©ployer un mod√®le plus avanc√© (embeddings ou ModernBERT) sur une infra cloud avec GPU.

- Remplacer le logging fichier par une stack de monitoring plus robuste (type Application Insights, Prometheus + Grafana, ou un APM manag√©).

- Mettre en place une vraie boucle de r√©entra√Ænement bas√©e sur les feedbacks collect√©s.

- Ajouter une gestion des versions de mod√®les plus fine (tagging de mod√®les, rollback, etc.).

- G√©rer d‚Äôautres langues ou d‚Äôautres r√©seaux sociaux (Instagram, Facebook, avis sites tiers, etc.).

---

```

```
